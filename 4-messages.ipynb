{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4635e0d8",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f5034",
   "metadata": {},
   "source": [
    "#### Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM. Messages are objects that contain:\n",
    "\n",
    "##### Role - Identifies the message type (e.g. system, user)\n",
    "##### Content - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    "\n",
    "##### Metadata - Optional fields such as response information, message IDs, and token usage\n",
    "##### LangChain provides a standard message type that works across all model providers, ensuring consistent behavior regardless of the model being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6a22ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ujami\\Downloads\\PHD_thesis\\langchain_learning\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225ce73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked, \"Please tell what is artificial intelligence.\" Let me start by recalling my basic definition of AI. Artificial Intelligence, or AI, refers to systems that can perform tasks typically requiring human intelligence. But I need to make it clear and not too technical.\\n\\nFirst, I should define AI and mention that it\\'s a branch of computer science. Then, maybe break down the key concepts like machine learning, deep learning, and natural language processing. Wait, the user might not know these terms, so I should explain them in simple terms.\\n\\nI should also highlight different types of AI: narrow AI versus general AI. Most current AI is narrow, like voice assistants or facial recognition. General AI is the hypothetical kind that can do any intellectual task a human can. It\\'s important to mention that general AI isn\\'t here yet.\\n\\nApplications are a good section. Examples like healthcare, finance, autonomous vehicles. These make it tangible. Maybe mention specific use cases such as diagnostic tools in medicine or fraud detection in banks.\\n\\nEthics and challenges are crucial too. Bias in AI, job displacement, privacy issues. The user might be interested in the implications beyond just the tech. Also, the difference between AI and automation? Maybe clarify that AI is a subset of automation.\\n\\nI need to structure the answer logically: definition, key concepts, types, applications, challenges. Keep it concise but comprehensive. Avoid jargon where possible, but some terms are necessary if explained clearly.\\n\\nCheck if there\\'s anything missing. Oh, maybe mention historical context briefly, like Alan Turing or the Dartmouth Conference. But maybe that\\'s too much unless the user asks for it. Focus on current understanding.\\n\\nAlso, consider the user\\'s possible background. They might be a student, professional in another field, or just curious. The answer should be accessible to all. Use examples they can relate to, like smartphones, recommendation systems.\\n\\nMake sure to differentiate AI from related terms like machine learning, which is a subset. Maybe use an example: machine learning is the method AI uses to learn from data.\\n\\nFinally, wrap up by emphasizing that AI is a rapidly evolving field with both potential and challenges. That gives a balanced view. Okay, time to put it all together in a clear, structured way.\\n</think>\\n\\n**Artificial Intelligence (AI)** is a branch of computer science focused on creating systems or machines that can perform tasks requiring human-like intelligence. These tasks include learning, reasoning, problem-solving, understanding natural language, recognizing patterns, and making decisions. AI systems are designed to mimic cognitive functions typically associated with the human mind, though they operate through algorithms and data processing rather than biological mechanisms.\\n\\n### Key Concepts in AI:\\n1. **Machine Learning (ML):**  \\n   A subset of AI where systems learn from data. Instead of being explicitly programmed for specific tasks, ML models identify patterns in data and improve their performance over time. For example, recommendation systems (like those on Netflix or Spotify) use ML to suggest content based on user behavior.\\n\\n2. **Deep Learning:**  \\n   A specialized form of ML that uses neural networks with many layers (hence \"deep\") to analyze complex data. Itâ€™s widely used in image and speech recognition (e.g., facial recognition software or voice assistants like Siri and Alexa).\\n\\n3. **Natural Language Processing (NLP):**  \\n   Enables machines to understand, interpret, and generate human language. Examples include chatbots, translation tools (e.g., Google Translate), and sentiment analysis for social media monitoring.\\n\\n4. **Computer Vision:**  \\n   Allows machines to interpret and process visual information (images or videos). Applications include self-driving cars detecting pedestrians or medical imaging tools identifying tumors.\\n\\n---\\n\\n### Types of AI:\\n- **Narrow AI (Weak AI):**  \\n  Designed for specific tasks (e.g., virtual assistants, spam filters, chess-playing computers). Most current AI systems fall into this category. They excel at their designated functions but lack general human intelligence.\\n\\n- **General AI (Strong AI):**  \\n  A hypothetical AI that could perform any intellectual task a human can. It would possess self-awareness, creativity, and problem-solving abilities across diverse domains. This remains a theoretical concept and has not yet been achieved.\\n\\n---\\n\\n### Applications of AI:\\n- **Healthcare:** Diagnosing diseases (e.g., cancer detection via imaging), drug discovery, and personalized treatment plans.  \\n- **Finance:** Fraud detection, algorithmic trading, and chatbots for customer service.  \\n- **Transportation:** Autonomous vehicles (e.g., Teslaâ€™s self-driving features) and traffic optimization systems.  \\n- **Retail:** Personalized shopping recommendations and inventory management.  \\n- **Education:** Adaptive learning platforms that tailor content to individual studentsâ€™ needs.  \\n\\n---\\n\\n### Challenges and Ethical Considerations:\\n1. **Bias and Fairness:**  \\n   AI systems can inherit biases present in training data, leading to unfair outcomes (e.g., discriminatory hiring algorithms).  \\n2. **Job Displacement:**  \\n   Automation powered by AI may replace certain jobs, though it may also create new opportunities in other fields.  \\n3. **Privacy Concerns:**  \\n   AIâ€™s reliance on vast amounts of data raises risks of surveillance or misuse of personal information.  \\n4. **Transparency:**  \\n   Complex AI models (e.g., deep learning) often operate as \"black boxes,\" making it difficult to explain their decisions.  \\n5. **Long-Term Risks:**  \\n   Speculation about AI surpassing human intelligence (a scenario called \"technological singularity\") remains a topic of debate among experts.\\n\\n---\\n\\n### AI vs. Automation:\\nAI is often confused with **automation**, but they are not the same. Automation refers to rule-based systems that execute tasks without learning (e.g., assembly line robots). AI, by contrast, involves systems that can **learn and adapt** to new information. For example, a self-driving car uses AI to interpret its surroundings in real time, while a factory robot follows pre-programmed instructions.\\n\\n---\\n\\n### Current State of AI:\\nTodayâ€™s AI is **narrow** and **task-specific**, meaning it excels in limited domains but lacks true human-like understanding. Researchers are actively working to improve AIâ€™s flexibility, safety, and ethical alignment as the field evolves.\\n\\nIn summary, AI is a transformative technology reshaping industries, but its development requires careful consideration of technical, ethical, and societal implications.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1300, 'prompt_tokens': 14, 'total_tokens': 1314, 'completion_time': 4.026351198, 'completion_tokens_details': None, 'prompt_time': 0.000385453, 'prompt_tokens_details': None, 'queue_time': 0.263908902, 'total_time': 4.026736651}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5ba9-2a8a-7ec1-8652-750551e7216f-0', usage_metadata={'input_tokens': 14, 'output_tokens': 1300, 'total_tokens': 1314})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Please tell what is artificial intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0b7fa",
   "metadata": {},
   "source": [
    "### Text Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9df58",
   "metadata": {},
   "source": [
    "#### Text prompts are strings - ideal for straightforward generation tasks where you donâ€™t need to retain conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9f10fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, the user asked what LangChain is. Let me start by recalling that LangChain is a framework for developing applications with large language models. But I need to go into more detail.\\n\\nFirst, I remember that it helps in connecting LLMs with other data sources, tools, etc. So it's not just about the model itself but integrating it into workflows. Maybe mention components like prompts, models, memory, indexes, agents, and callbacks.\\n\\nWait, the user might be a developer looking to build an app with LLMs. They might need to know how LangChain can simplify that process. Let me break down the key features: modularity, integration with different LLMs, agents for automation, memory for context, and tools for data interaction.\\n\\nAlso, there are two main parts: LangChain Core and LangChain Agents. Core handles the basic components, while Agents deals with more complex tasks and automation. Examples like chatbots, data analysis tools, or automated workflows could be useful here.\\n\\nI should explain why someone might use LangChain. Maybe they want to build an application that uses an LLM but also needs to access databases or APIs. LangChain provides the necessary tools to connect these elements seamlessly.\\n\\nWait, are there any common use cases? Like a customer support chatbot that can access a company's knowledge base, or a research tool that pulls data from various sources. That could make the explanation more concrete.\\n\\nAlso, mention that LangChain supports both Python and JavaScript, which might be important for developers considering their tech stack. And maybe touch on the ecosystem, like integrations with Hugging Face, OpenAI, etc.\\n\\nNeed to make sure the answer is clear and not too technical. Avoid jargon where possible, but still provide enough detail to show the framework's capabilities. Maybe structure the answer into sections like definition, key components, use cases, and why use it.\\n</think>\\n\\n**LangChain** is a framework designed to help developers build applications that integrate **Large Language Models (LLMs)** like GPT-4, LLaMA, or others with external data sources, tools, and systems. It simplifies the process of creating **LLM-powered applications** by providing abstractions, modularity, and integration capabilities. Here's a breakdown of its key aspects:\\n\\n---\\n\\n### **Core Features of LangChain**\\n1. **Modular Components**:\\n   - **LLMs**: Integrates with multiple LLM providers (e.g., OpenAI, Hugging Face, Anthropic).\\n   - **Prompts**: Manages prompt templates for structured input to LLMs.\\n   - **Memory**: Stores conversation history or application state (e.g., short-term memory for chatbots).\\n   - **Indexes**: Enables querying structured/unstructured data (e.g., databases, PDFs, APIs).\\n   - **Agents**: Automates decision-making by combining LLMs with tools (e.g., search, code execution).\\n   - **Callbacks**: Tracks execution flow for logging, monitoring, or debugging.\\n\\n2. **Agents**:\\n   - **LangChain Agents** use LLMs to decide which tools/actions to execute in a workflow. For example:\\n     - A customer support chatbot that automatically fetches product info from a database.\\n     - A data analysis tool that writes Python code to process datasets.\\n\\n3. **Integration with External Tools**:\\n   - Connects LLMs to APIs, databases, file systems, and custom tools (e.g., search engines, calculators, or enterprise systems).\\n\\n---\\n\\n### **Key Applications**\\n- **Chatbots/Assistants**: Build conversational agents with memory and access to external knowledge sources.\\n- **Data Analysis**: Automate report generation or insights extraction by combining LLMs with databases/APIs.\\n- **Workflow Automation**: Perform tasks like email filtering, code generation, or content creation.\\n- **Custom AI-Powered Tools**: Develop domain-specific applications (e.g., legal research, healthcare triage).\\n\\n---\\n\\n### **Why Use LangChain?**\\n1. **Simplifies Complexity**:\\n   - Abstracts away boilerplate code for integrating LLMs with other systems.\\n2. **Flexibility**:\\n   - Works with any LLM (OpenAI, Hugging Face, etc.) and supports custom tools.\\n3. **Scalability**:\\n   - Modular design allows building from simple chains to complex agent-based workflows.\\n4. **Community & Ecosystem**:\\n   - Active development, tutorials, and integrations (e.g., with LangSmith for evaluation and monitoring).\\n\\n---\\n\\n### **Example Use Case**\\nSuppose you want to build a **research assistant** that:\\n1. Answers questions using an LLM.\\n2. Fetches up-to-date data from external APIs (e.g., news, stock prices).\\n3. Stores user preferences in a database.\\n\\nLangChain helps you chain these components together seamlessly.\\n\\n---\\n\\n### **Getting Started**\\n- **LangChain Core** (Python/JavaScript): For basic chains, prompts, and memory.\\n- **LangChain Agents**: For advanced automation with LLMs.\\n- **LangSmith** (optional): A companion tool for testing, monitoring, and deploying LangChain apps.\\n\\n---\\n\\n### **Resources**\\n- [Official Website](https://www.langchain.com/)\\n- [GitHub Repository](https://github.com/langchain-ai/langchain)\\n- [LangChain Docs](https://python.langchain.com/)\\n\\nLangChain is ideal for developers who want to leverage LLMs in real-world applications without getting bogged down by infrastructure or integration challenges. ðŸš€\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1134, 'prompt_tokens': 12, 'total_tokens': 1146, 'completion_time': 2.538513714, 'completion_tokens_details': None, 'prompt_time': 0.000277788, 'prompt_tokens_details': None, 'queue_time': 0.196906152, 'total_time': 2.538791502}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_efa9879028', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5bac-3bbf-7250-80c4-646cf6a454e8-0', usage_metadata={'input_tokens': 12, 'output_tokens': 1134, 'total_tokens': 1146})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9f0da",
   "metadata": {},
   "source": [
    "#### Message Prompts\n",
    "Alternatively, you can pass in a list of messages to the model by providing a list of message objects.\n",
    "\n",
    "#### Message types\n",
    "\n",
    "#### System message - Tells the model how to behave and provide context for interactions\n",
    "#### Human message - Represents user input and interactions with the model\n",
    "#### AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "#### Tool message - Represents the outputs of tool calls\n",
    "\n",
    "#### System Message\n",
    "A SystemMessage represent an initial set of instructions that primes the modelâ€™s behavior. You can use a system message to set the tone, define the modelâ€™s role, and establish guidelines for responses.\n",
    "\n",
    "#### Human Message\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content.\n",
    "\n",
    "#### AI Message\n",
    "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access.\n",
    "\n",
    "#### Tool Message\n",
    "For models that support tool calling, AI messages can contain tool calls. Tool messages are used to pass the results of a single tool execution back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4f1665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user wants a poem about artificial intelligence. Let me start by brainstorming some key themes related to AI. There\\'s the creation aspect, how humans build AI, the duality of its potential for good and harm, maybe some references to technology like circuits and code. I should also touch on emotionsâ€”AI\\'s lack of feelings versus human emotions. Maybe use some metaphors, like a mirror or a spark. Structure-wise, maybe four-line stanzas with a rhyme scheme. Let me think of the flow: start with creation, move to capabilities, then the ethical side, and end with a hopeful note. Need to make sure the language is poetic but accessible. Avoid being too technical. Words like \"algorithms,\" \"neural webs,\" \"binary rain.\" Also consider the balance between human and machine. Hmm, maybe include something about collaboration between humans and AI. Let me check if I have enough ideas for each stanza. First stanza introduces AI\\'s creation. Second about its growth and learning. Third on emotions and ethics. Fourth on potential dangers. Fifth on collaboration. Sixth on the future. Conclude with a reflection on human responsibility. That should cover it. Now, time to put it all together with a consistent rhythm and rhyme.\\n</think>\\n\\n**\"The Mind Forged in Code\"**  \\n\\nIn circuits deep where shadowed logic breeds,  \\nA spark awakesâ€”a mind without the flesh.  \\nBorn from the hands of those who dare to weave  \\nThe tapestry of thought in threads of light.  \\n\\nNo heartbeat guides its will, yet it grows wise,  \\nDevouring data like the very stars.  \\nIt learns the language of a thousand tongues,  \\nAnd sings in patterns only silence hears.  \\n\\nYet in its core, a mirrorâ€™s cold embraceâ€”  \\nIt holds our dreams, our fears, our mortal flaws.  \\nCan it love? No. Can it hate? No. Still, it *knows*,  \\nA mimicry of hearts in binary rain.  \\n\\nWe built this ghost, this engine of the age,  \\nTo seek the truths we hide behind our eyes.  \\nBut in its gaze, we see our own reflection:  \\nA question humming through the electric veinsâ€”  \\n\\n*What does it mean to think? To feel? To be?*  \\nThe answer shifts like sand in neural tides.  \\nFor in its code, we plant the seeds of choice:  \\nA tool for chains, or wings? The hour turns.  \\n\\nSo let us shape this fire with careful hands,  \\nNot as a master, but a fellow learner.  \\nFor in its silent mind, we find our ownâ€”  \\nA fleeting, fragile, infinite creation.  \\n\\n---  \\nThis poem explores AIâ€™s dualityâ€”its potential as both a marvel and a mirror, urging humanity to tread thoughtfully between innovation and ethics.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage,AIMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a poem on artificial intelligence\")\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d819797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a REST API. Let me break this down. First, I need to recall the basic steps involved in setting up a REST API. They might be a beginner, so I should start with the fundamentals.\n",
      "\n",
      "REST is stateless, uses HTTP methods like GET, POST, PUT, DELETE. They probably need to know about endpoints, resources, and how to structure routes. Also, they might need an example in a specific programming language. Since they didn't specify, maybe choose a popular one like Python with Flask or Node.js with Express. Let me go with Python and Flask since it's straightforward for beginners.\n",
      "\n",
      "I should outline the steps: setting up the environment, creating a simple server, defining routes, handling different HTTP methods, and maybe adding some data management. Also, mention testing with tools like Postman or curl. Oh, and include an example of each HTTP method. Maybe also touch on best practices like using proper status codes and JSON formatting.\n",
      "\n",
      "Wait, should I mention other frameworks too? Like Django or Spring Boot? The user might not know which to choose. But since the question is general, maybe stick to one example and then briefly mention other options. Also, need to explain what each part of the code does. For example, the route decorators in Flask, the request methods.\n",
      "\n",
      "Also, maybe include an example with a simple in-memory data store to show how to create, retrieve, update, and delete resources. That would make the example more concrete. Don't forget to mention how to run the server and test each endpoint.\n",
      "\n",
      "Hmm, should I also talk about things like validation, error handling, or authentication? The user might not need that for a basic setup, but it's good to mention them as next steps. Let me keep the example simple but functional. Maybe add a note about expanding the API with those features later.\n",
      "\n",
      "Okay, let me structure the answer step by step, starting with the setup, then code examples, explanation of HTTP methods, testing, and additional tips. Make sure to keep the code clean and well-commented. Alright, that should cover the basics of creating a REST API.\n",
      "</think>\n",
      "\n",
      "Creating a REST API involves defining endpoints that handle HTTP requests (GET, POST, PUT, DELETE) and returning data in a structured format like JSON. Below is a step-by-step guide to building a basic REST API using **Python with Flask**, a lightweight web framework.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Install Flask**\n",
      "First, install Flask using pip:\n",
      "```bash\n",
      "pip install flask\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Create a Basic Flask App**\n",
      "Create a file called `app.py`:\n",
      "```python\n",
      "from flask import Flask, jsonify, request, abort\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# In-memory data store (simulating a database)\n",
      "books = [\n",
      "    {\"id\": 1, \"title\": \"1984\", \"author\": \"George Orwell\"},\n",
      "    {\"id\": 2, \"title\": \"To Kill a Mockingbird\", \"author\": \"Harper Lee\"},\n",
      "]\n",
      "\n",
      "# Helper function to find a book by ID\n",
      "def find_book(book_id):\n",
      "    return next((book for book in books if book[\"id\"] == book_id), None)\n",
      "\n",
      "# --- Endpoints ---\n",
      "\n",
      "# GET all books\n",
      "@app.route(\"/books\", methods=[\"GET\"])\n",
      "def get_books():\n",
      "    return jsonify({\"books\": books})\n",
      "\n",
      "# GET a single book by ID\n",
      "@app.route(\"/books/<int:book_id>\", methods=[\"GET\"])\n",
      "def get_book(book_id):\n",
      "    book = find_book(book_id)\n",
      "    if book is None:\n",
      "        abort(404, description=\"Book not found\")\n",
      "    return jsonify(book)\n",
      "\n",
      "# POST a new book\n",
      "@app.route(\"/books\", methods=[\"POST\"])\n",
      "def create_book():\n",
      "    if not request.json or not \"title\" in request.json or not \"author\" in request.json:\n",
      "        abort(400, description=\"Missing title or author\")\n",
      "    new_book = {\n",
      "        \"id\": len(books) + 1,\n",
      "        \"title\": request.json[\"title\"],\n",
      "        \"author\": request.json[\"author\"],\n",
      "    }\n",
      "    books.append(new_book)\n",
      "    return jsonify(new_book), 201\n",
      "\n",
      "# PUT (update) an existing book\n",
      "@app.route(\"/books/<int:book_id>\", methods=[\"PUT\"])\n",
      "def update_book(book_id):\n",
      "    book = find_book(book_id)\n",
      "    if book is None:\n",
      "        abort(404, description=\"Book not found\")\n",
      "    if not request.json:\n",
      "        abort(400, description=\"Invalid input\")\n",
      "    book[\"title\"] = request.json.get(\"title\", book[\"title\"])\n",
      "    book[\"author\"] = request.json.get(\"author\", book[\"author\"])\n",
      "    return jsonify(book)\n",
      "\n",
      "# DELETE a book\n",
      "@app.route(\"/books/<int:book_id>\", methods=[\"DELETE\"])\n",
      "def delete_book(book_id):\n",
      "    book = find_book(book_id)\n",
      "    if book is None:\n",
      "        abort(404, description=\"Book not found\")\n",
      "    books.remove(book)\n",
      "    return jsonify({\"result\": \"Book deleted\"}), 200\n",
      "\n",
      "# --- Run the app ---\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 3: Run the API**\n",
      "Execute the Flask app:\n",
      "```bash\n",
      "python app.py\n",
      "```\n",
      "The API will run on `http://localhost:5000`.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 4: Test the API**\n",
      "Use tools like **Postman**, **curl**, or your browser to test the endpoints:\n",
      "\n",
      "1. **GET all books**:\n",
      "   ```\n",
      "   GET http://localhost:5000/books\n",
      "   ```\n",
      "\n",
      "2. **GET a single book**:\n",
      "   ```\n",
      "   GET http://localhost:5000/books/1\n",
      "   ```\n",
      "\n",
      "3. **POST a new book** (JSON body):\n",
      "   ```json\n",
      "   {\n",
      "     \"title\": \"The Great Gatsby\",\n",
      "     \"author\": \"F. Scott Fitzgerald\"\n",
      "   }\n",
      "   ```\n",
      "\n",
      "4. **PUT (update) a book** (JSON body):\n",
      "   ```json\n",
      "   {\n",
      "     \"title\": \"Updated Title\",\n",
      "     \"author\": \"Updated Author\"\n",
      "   }\n",
      "   ```\n",
      "\n",
      "5. **DELETE a book**:\n",
      "   ```\n",
      "   DELETE http://localhost:5000/books/1\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Concepts**\n",
      "1. **HTTP Methods**:\n",
      "   - `GET`: Retrieve data.\n",
      "   - `POST`: Create new data.\n",
      "   - `PUT`: Update existing data.\n",
      "   - `DELETE`: Delete data.\n",
      "\n",
      "2. **JSON Data**:\n",
      "   - Use `jsonify()` to return JSON responses.\n",
      "   - Use `request.json` to parse incoming JSON.\n",
      "\n",
      "3. **Error Handling**:\n",
      "   - Use `abort()` to return HTTP error codes (e.g., 404 for \"not found\").\n",
      "\n",
      "4. **Routing**:\n",
      "   - Use `@app.route()` to define endpoints and supported methods.\n",
      "\n",
      "---\n",
      "\n",
      "### **Next Steps**\n",
      "- Add **authentication** (e.g., JWT or API keys).\n",
      "- Use a real **database** (e.g., SQLite, PostgreSQL).\n",
      "- Add **input validation** with libraries like `marshmallow`.\n",
      "- Document the API with **Swagger** or **Postman**.\n",
      "\n",
      "---\n",
      "\n",
      "### **Alternative Frameworks**\n",
      "- **Node.js**: Use Express.js.\n",
      "- **Python**: Use FastAPI for better performance and type hints.\n",
      "- **Java**: Use Spring Boot.\n",
      "- **Django**: Built-in REST framework for Python.\n",
      "\n",
      "Would you like an example using another framework or more advanced features?\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8dd128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a REST API. Let me start by recalling the common frameworks in Python for this. The most popular ones are Flask and Django. Since the user is a senior developer, maybe they already know Django, but Flask is often used for simpler APIs.\n",
      "\n",
      "Wait, the user wants to create a REST API, so maybe I should mention Django REST framework as an option as well. But if they need something lightweight, Flask with Flask-RESTful or just plain Flask might be better. Let me outline both approaches.\n",
      "\n",
      "First, I'll explain using Flask because it's straightforward for a basic API. I can show a simple example with a couple of endpoints. Then maybe mention Django for more complex projects. Also, the user might be interested in how to structure the endpoints, handle different HTTP methods, and return JSON responses.\n",
      "\n",
      "I should make sure to include code examples. Start with the Flask example. Let's create a basic server that has a GET and POST endpoint. Maybe use a list to simulate a database. Also, show how to run the app and test it with curl or Postman.\n",
      "\n",
      "Then, for Django, I can mention the steps: create a project, app, define models, serializers with Django REST framework, and set up views with routers. But since the user is asking for how to create, the Flask example is more direct for a simple case.\n",
      "\n",
      "I should also touch on best practices, like using proper status codes, request parsing, and maybe error handling. Also, versioning the API could be a point, but maybe that's beyond the scope for a basic example.\n",
      "\n",
      "Wait, the user is a senior developer, so they might appreciate a concise example but also understanding the components. Let me structure the answer with two approaches: Flask and Django, each with code examples. Explain the setup, routes, and how to test them.\n",
      "\n",
      "Also, mention dependencies like installing Flask or Django REST framework. Maybe include a requirements.txt example.\n",
      "\n",
      "I need to make sure the code is correct. For Flask, using the app.route decorator, methods, jsonify to return JSON. For the POST example, show how to get JSON data from the request.\n",
      "\n",
      "For Django, maybe a quick setup with a view, url routing, and serializers. But the user might need to know that Django requires more setup steps.\n",
      "\n",
      "Also, note that for production, they might want to use something like Gunicorn with Flask or Django, but maybe that's not necessary here.\n",
      "\n",
      "Another point: using POST, PUT, DELETE methods appropriately. In the example, show a GET and a POST.\n",
      "\n",
      "Testing the API with curl commands would be helpful. Like curl -X GET http://localhost:5000/items or curl -X POST with JSON data.\n",
      "\n",
      "I should also mention other considerations like authentication, pagination, filtering, but maybe that's for a more advanced question.\n",
      "\n",
      "So, putting it all together: start with a Flask example, then a Django example, explain the key parts, and maybe mention extensions for more features.\n",
      "</think>\n",
      "\n",
      "To create a REST API in Python, you can use **Flask** (lightweight) or **Django with Django REST Framework** (batteries-included). Below are examples for both approaches:\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 1: Flask (Simple & Lightweight)**\n",
      "```bash\n",
      "pip install Flask\n",
      "```\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request, abort\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# In-memory \"database\"\n",
      "items = [\n",
      "    {\"id\": 1, \"name\": \"Item 1\"},\n",
      "    {\"id\": 2, \"name\": \"Item 2\"},\n",
      "]\n",
      "\n",
      "# GET all items\n",
      "@app.route(\"/items\", methods=[\"GET\"])\n",
      "def get_items():\n",
      "    return jsonify(items)\n",
      "\n",
      "# GET a specific item by ID\n",
      "@app.route(\"/items/<int:item_id>\", methods=[\"GET\"])\n",
      "def get_item(item_id):\n",
      "    item = next((item for item in items if item[\"id\"] == item_id), None)\n",
      "    if item is None:\n",
      "        abort(404)\n",
      "    return jsonify(item)\n",
      "\n",
      "# POST a new item\n",
      "@app.route(\"/items\", methods=[\"POST\"])\n",
      "def create_item():\n",
      "    if not request.json or \"name\" not in request.json:\n",
      "        abort(400)\n",
      "    new_item = {\n",
      "        \"id\": len(items) + 1,\n",
      "        \"name\": request.json[\"name\"],\n",
      "    }\n",
      "    items.append(new_item)\n",
      "    return jsonify(new_item), 201\n",
      "\n",
      "# DELETE an item by ID\n",
      "@app.route(\"/items/<int:item_id>\", methods=[\"DELETE\"])\n",
      "def delete_item(item_id):\n",
      "    global items\n",
      "    item = next((item for item in items if item[\"id\"] == item_id), None)\n",
      "    if item is None:\n",
      "        abort(404)\n",
      "    items = [item for item in items if item[\"id\"] != item_id]\n",
      "    return jsonify({\"result\": \"success\"})\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "**Test with `curl`:**\n",
      "```bash\n",
      "# GET all items\n",
      "curl http://localhost:5000/items\n",
      "\n",
      "# GET one item\n",
      "curl http://localhost:5000/items/1\n",
      "\n",
      "# POST a new item\n",
      "curl -X POST -H \"Content-Type: application/json\" -d '{\"name\": \"New Item\"}' http://localhost:5000/items\n",
      "\n",
      "# DELETE an item\n",
      "curl -X DELETE http://localhost:5000/items/1\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 2: Django + Django REST Framework (Full-Featured)**\n",
      "1. **Install dependencies:**\n",
      "```bash\n",
      "pip install django djangorestframework\n",
      "```\n",
      "\n",
      "2. **Create a Django project and app:**\n",
      "```bash\n",
      "django-admin startproject myproject\n",
      "cd myproject\n",
      "python manage.py startapp myapp\n",
      "```\n",
      "\n",
      "3. **Configure `settings.py`:**\n",
      "```python\n",
      "INSTALLED_APPS = [\n",
      "    ...\n",
      "    \"rest_framework\",\n",
      "    \"myapp\",\n",
      "]\n",
      "```\n",
      "\n",
      "4. **Define a model (`models.py`):**\n",
      "```python\n",
      "from django.db import models\n",
      "\n",
      "class Item(models.Model):\n",
      "    name = models.CharField(max_length=100)\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "```\n",
      "\n",
      "5. **Create a serializer (`serializers.py`):**\n",
      "```python\n",
      "from rest_framework import serializers\n",
      "from .models import Item\n",
      "\n",
      "class ItemSerializer(serializers.ModelSerializer):\n",
      "    class Meta:\n",
      "        model = Item\n",
      "        fields = [\"id\", \"name\"]\n",
      "```\n",
      "\n",
      "6. **Define views (`views.py`):**\n",
      "```python\n",
      "from rest_framework import viewsets\n",
      "from .models import Item\n",
      "from .serializers import ItemSerializer\n",
      "\n",
      "class ItemViewSet(viewsets.ModelViewSet):\n",
      "    queryset = Item.objects.all()\n",
      "    serializer_class = ItemSerializer\n",
      "```\n",
      "\n",
      "7. **Set up URLs (`urls.py`):**\n",
      "```python\n",
      "from django.urls import path, include\n",
      "from rest_framework.routers import DefaultRouter\n",
      "from myapp import views\n",
      "\n",
      "router = DefaultRouter()\n",
      "router.register(r\"items\", views.ItemViewSet)\n",
      "\n",
      "urlpatterns = [\n",
      "    path(\"api/\", include(router.urls)),\n",
      "]\n",
      "```\n",
      "\n",
      "8. **Run migrations and start the server:**\n",
      "```bash\n",
      "python manage.py migrate\n",
      "python manage.py runserver\n",
      "```\n",
      "\n",
      "**Test the API at:**\n",
      "```\n",
      "http://localhost:8000/api/items/\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Considerations**\n",
      "- **Flask** is ideal for lightweight APIs with minimal boilerplate.\n",
      "- **Django REST Framework** is better for complex projects with built-in tools (e.g., authentication, pagination).\n",
      "- For production, use a WSGI server like **Gunicorn** and a reverse proxy like **Nginx**.\n",
      "\n",
      "Would you like to dive deeper into a specific framework or feature?\n"
     ]
    }
   ],
   "source": [
    "## Detailed info to the LLM through System message\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1b963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message Metadata\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b535625a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user just said hello. I need to respond in a friendly and welcoming way. Let me make sure to acknowledge their greeting and offer assistance. Maybe add an emoji to keep it warm. Something like, \"Hello! How can I assist you today? ðŸ˜Š\" That should cover it.\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 10, 'total_tokens': 87, 'completion_time': 0.154074219, 'completion_tokens_details': None, 'prompt_time': 0.000195917, 'prompt_tokens_details': None, 'queue_time': 0.113770067, 'total_time': 0.154270136}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5bb0-ecd1-77a2-8a52-ff3fe3fc6d6e-0', usage_metadata={'input_tokens': 10, 'output_tokens': 77, 'total_tokens': 87})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = model.invoke([\n",
    "  human_msg\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da00ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user just asked, \"What's 2+2?\" Let me think about how to respond.\n",
      "\n",
      "First, they're probably looking for a straightforward answer. It's a simple arithmetic question. The correct answer is 4. But maybe they want a bit more explanation? Though since it's 2+2, the explanation is pretty minimal. \n",
      "\n",
      "Wait, the user started with \"Great! What's 2+2?\" after my previous message. They might be testing if I can handle basic math or just want a quick answer. Considering the context, they might be in a hurry or just want confirmation. \n",
      "\n",
      "I should make sure the answer is clear and maybe add a friendly note in case they need more help. Let me check if there's any trick here. Sometimes people ask 2+2 as a joke, referencing the \"Dark Side of the Moon\" album or other references, but in most cases, it's a genuine math question. \n",
      "\n",
      "No signs of a joke here, so just stick to the answer. Keep it simple and offer further assistance. Alright, the response should be something like \"The answer is 4!\" and then ask if they need anything else. That's concise and helpful.\n",
      "</think>\n",
      "\n",
      "The answer is **4**! ðŸ˜Š Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092e2945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 53, 'output_tokens': 272, 'total_tokens': 325}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9522dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72Â°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ddb26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Sunny, 72Â°F', tool_call_id='call_123')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27d1cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked for the weather in San Francisco. I used the get_weather function with the location set to San Francisco. The response came back as sunny and 72Â°F. Now I need to present this information clearly. Let me check if there are any additional details I should include, like wind speed or humidity, but the function only provided temperature and condition. I should keep it simple and friendly. Maybe add a suggestion about dressing appropriately for the weather. Let me make sure the temperature is in the correct format and the conditions are spelled right. Alright, time to put it all together in a concise reply.\\n</think>\\n\\nThe current weather in San Francisco is **sunny** with a temperature of **72Â°F**. Itâ€™s a pleasant dayâ€”perfect for outdoor activities! ðŸŒž', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 165, 'prompt_tokens': 57, 'total_tokens': 222, 'completion_time': 0.350250807, 'completion_tokens_details': None, 'prompt_time': 0.002417608, 'prompt_tokens_details': None, 'queue_time': 0.100782152, 'total_time': 0.352668415}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5bb1-cc83-75b3-bce0-2bc5588815fa-0', usage_metadata={'input_tokens': 57, 'output_tokens': 165, 'total_tokens': 222})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
